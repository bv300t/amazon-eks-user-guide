include::../attributes.txt[]

[.topic]
[#ml-tutorials]
= Try tutorials for deploying Machine Learning workloads on EKS
:info_titleabbrev: Try tutorials for ML on EKS

If you are interested in setting up Machine Learning platforms and frameworks in EKS, explore the tutorials described in this page.
These tutorials cover everything from patterns for making the best use of GPU processors to choosing modeling tools to building frameworks for specialized industries.

== Build generative AI platforms on EKS

* link:containers/deploy-generative-ai-models-on-amazon-eks/[Deploy Generative AI Models on Amazon EKS,type="blog"]
* link:containers/building-multi-tenant-jupyterhub-platforms-on-amazon-eks/[Building multi-tenant JupyterHub Platforms on Amazon EKS,type="blog"]

== Run specialized generative AI frameworks on EKS

* link:machine-learning/accelerate-your-generative-ai-distributed-training-workloads-with-the-nvidia-nemo-framework-on-amazon-eks/[Accelerate your generative AI distributed training workloads with the NVIDIA NeMo Framework on Amazon EKS,type="blog"]
* link:opensource/running-torchserve-on-amazon-elastic-kubernetes-service/[Running TorchServe on Amazon Elastic Kubernetes Service,type="blog"]

== Maximize NVIDIA GPU performance for ML on EKS

* Implement GPU sharing to efficiently use NVIDIA GPUs for your EKS clusters:
+
link:containers/gpu-sharing-on-amazon-eks-with-nvidia-time-slicing-and-accelerated-ec2-instances/[GPU sharing on Amazon EKS with NVIDIA time-slicing and accelerated EC2 instances,type="blog"]

* Use Multi-Instance GPUs (MIGs) and NIM microservices to run more pods per GPU on your EKS clusters:
+
link:containers/maximizing-gpu-utilization-with-nvidias-multi-instance-gpu-mig-on-amazon-eks-running-more-pods-per-gpu-for-enhanced-performance/[Maximizing GPU utilization with NVIDIA's Multi-Instance GPU (MIG) on Amazon EKS: Running more pods per GPU for enhanced performance,type="blog"]

* link:machine-learning/build-and-deploy-a-scalable-machine-learning-system-on-kubernetes-with-kubeflow-on-aws/[Build and deploy a scalable machine learning system on Kubernetes with Kubeflow on {aws},type="blog"]

== Run video encoding workloads on EKS

* link:containers/delivering-video-content-with-fractional-gpus-in-containers-on-amazon-eks/[Delivering video content with fractional GPUs in containers on Amazon EKS,type="blog"]

== Accelerate image loading for inference workloads

* link:containers/how-h2o-ai-optimized-and-secured-their-ai-ml-infrastructure-with-karpenter-and-bottlerocket/[How H2O.ai optimized and secured their AI/ML infrastructure with Karpenter and Bottlerocket,type="blog"]

== Monitoring ML workloads

* link:mt/monitoring-gpu-workloads-on-amazon-eks-using-aws-managed-open-source-services/[Monitoring GPU workloads on Amazon EKS using {aws} managed open-source services,type="blog"]
* link:machine-learning/enable-pod-based-gpu-metrics-in-amazon-cloudwatch/[Enable pod-based GPU metrics in Amazon CloudWatch,type="blog"]

== Announcements for ML on EKS

* link:containers/bottlerocket-support-for-nvidia-gpus/[Bottlerocket support for NVIDIA GPUs,type="blog"]
* link:containers/utilizing-nvidia-multi-instance-gpu-mig-in-amazon-ec2-p4d-instances-on-amazon-elastic-kubernetes-service-eks/[Utilizing NVIDIA Multi-Instance GPU (MIG) in Amazon EC2 P4d Instances on Amazon Elastic Kubernetes Service,type="blog"]
* link:containers/deploying-managed-p4d-instances-in-amazon-elastic-kubernetes-service/[Deploying managed P4d Instances in Amazon Elastic Kubernetes Service with NVIDIA GPUDirectRDMA,type="blog"]
