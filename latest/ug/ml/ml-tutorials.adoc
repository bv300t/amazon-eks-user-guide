[.topic]
[#ml-tutorials]
= Try tutorials for deploying Machine Learning workloads on EKS
:info_titleabbrev: Try tutorials for ML on EKS

include::../attributes.txt[]

If you are interested in setting up Machine Learning platforms and frameworks in EKS, explore the tutorials described in this page.
These tutorials cover everything from patterns for making the best use of GPU processors to choosing modeling tools to building frameworks for specialized industries.

== Build generative AI platforms on EKS

*  link:containers/deploy-generative-ai-models-on-amazon-eks/[Deploy Generative AI Models on Amazon EKS,type="blog"]
*  link:containers/building-multi-tenant-jupyterhub-platforms-on-amazon-eks/[Building multi-tenant JupyterHub Platforms on Amazon EKS,type="blog"]
*  link:containers/run-spark-rapids-ml-workloads-with-gpus-on-amazon-emr-on-eks/[Run Spark-RAPIDS ML workloads with GPUs on Amazon EMR on EKS,type="blog"]

== Run specialized generative AI frameworks on EKS

* link:hpc/accelerate-drug-discovery-with-nvidia-bionemo-framework-on-amazon-eks/[Accelerate drug discovery with NVIDIA BioNeMo Framework on Amazon EKS,type="blog"]
* link:containers/host-the-whisper-model-with-streaming-mode-on-amazon-eks-and-ray-serve/[Host the Whisper Model with Streaming Mode on Amazon EKS and Ray Serve,type="blog"]
* link:machine-learning/accelerate-your-generative-ai-distributed-training-workloads-with-the-nvidia-nemo-framework-on-amazon-eks/[Accelerate your generative AI distributed training workloads with the NVIDIA NeMo Framework on Amazon EKS,type="blog"]
*  link:publicsector/virtualizing-satcom-operations-aws/[Virtualizing satellite communication operations with {aws},type="blog"]
*  link:opensource/running-torchserve-on-amazon-elastic-kubernetes-service/[Running TorchServe on Amazon Elastic Kubernetes Service,type="blog"]

== Maximize NVIDIA GPU performance for ML on EKS

* Implement GPU sharing to efficiently use NVIDIA GPUs for your EKS clusters:
+
link:containers/gpu-sharing-on-amazon-eks-with-nvidia-time-slicing-and-accelerated-ec2-instances/[GPU sharing on Amazon EKS with NVIDIA time-slicing and accelerated EC2 instances,type="blog"]

* Use Multi-Instance GPUs (MIGs) and NIM microservices to run more pods per GPU on your EKS clusters:
+
link:containers/maximizing-gpu-utilization-with-nvidias-multi-instance-gpu-mig-on-amazon-eks-running-more-pods-per-gpu-for-enhanced-performance/[Maximizing GPU utilization with NVIDIA's Multi-Instance GPU (MIG) on Amazon EKS: Running more pods per GPU for enhanced performance,type="blog"]

* Leverage NVIDIA NIM microservices to optimize inference workloads using optimized microservices to deploy AI models at scale:
+
link:hpc/deploying-generative-ai-applications-with-nvidia-nims-on-amazon-eks/[Part 1: Deploying generative AI applications with NVIDIA NIMs on Amazon EKS,type="blog"]
+
link:hpc/deploying-generative-ai-applications-with-nvidia-nim-microservices-on-amazon-elastic-kubernetes-service-amazon-eks-part-2/[Part 2: Deploying Generative AI Applications with NVIDIA NIM Microservices on Amazon Elastic Kubernetes Service (Amazon EKS),type="blog"]

* link:containers/scaling-a-large-language-model-with-nvidia-nim-on-amazon-eks-with-karpenter/[Scaling a Large Language Model with NVIDIA NIM on Amazon EKS with Karpenter,type="blog"]


*  link:machine-learning/build-and-deploy-a-scalable-machine-learning-system-on-kubernetes-with-kubeflow-on-aws/[Build and deploy a scalable machine learning system on Kubernetes with Kubeflow on {aws},type="blog"]

== Run video encoding workloads on EKS

* link:containers/delivering-video-content-with-fractional-gpus-in-containers-on-amazon-eks/[Delivering video content with fractional GPUs in containers on Amazon EKS,type="blog"]

== Accelerate image loading for inference workloads

* link:containers/how-h2o-ai-optimized-and-secured-their-ai-ml-infrastructure-with-karpenter-and-bottlerocket/[How H2O.ai optimized and secured their AI/ML infrastructure with Karpenter and Bottlerocket,type="blog"]

== Testimonials for ML on EKS

*  link:containers/quora-3x-faster-machine-learning-25-lower-costs-with-nvidia-triton-on-amazon-eks/[Quora achieved 3x lower latency and 25% lower Costs by modernizing model serving with Nvidia Triton on Amazon EKS,type="blog"]

== Monitoring ML workloads

* link:mt/monitoring-gpu-workloads-on-amazon-eks-using-aws-managed-open-source-services/[Monitoring GPU workloads on Amazon EKS using {aws} managed open-source services,type="blog"]
* link:machine-learning/enable-pod-based-gpu-metrics-in-amazon-cloudwatch/[Enable pod-based GPU metrics in Amazon CloudWatch,type="blog"]

== Announcements for ML on EKS

* link:containers/bottlerocket-support-for-nvidia-gpus/[Bottlerocket support for NVIDIA GPUs,type="blog"]
* link:aws/new-ec2-instances-g5-with-nvidia-a10g-tensor-core-gpus/[New ‚Äì EC2 Instances (G5) with NVIDIA A10G Tensor Core GPUs,type="blog"]
* link:containers/utilizing-nvidia-multi-instance-gpu-mig-in-amazon-ec2-p4d-instances-on-amazon-elastic-kubernetes-service-eks/[Utilizing NVIDIA Multi-Instance GPU (MIG) in Amazon EC2 P4d Instances on Amazon Elastic Kubernetes Service,type="blog"]
* link:aws/new-gpu-equipped-ec2-p4-instances-for-machine-learning-hpc/[New ‚Äì GPU-Equipped EC2 P4 Instances for Machine Learning & HPC,type="blog"]
* link:machine-learning/amazon-ec2-p5e-instances-are-generally-available/[Amazon EC2 P5e instances are generally available,type="blog"]
* link:containers/deploying-managed-p4d-instances-in-amazon-elastic-kubernetes-service/[Deploying managed P4d Instances in Amazon Elastic Kubernetes Service with NVIDIA GPUDirectRDMA,type="blog"]
* link:machine-learning/establishing-an-ai-ml-center-of-excellence/[Establishing an AI/ML center of excellence,type="blog"]


üìù https://github.com/search?q=repo%3Aawsdocs%2Famazon-eks-user-guide+%5B%23ml-tutorials%5D&type=code[Edit this page on GitHub]