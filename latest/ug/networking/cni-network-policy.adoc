[.topic]
[#cni-network-policy]
= Limit [.noloc]`Pod` traffic with [.noloc]`Kubernetes` network policies
:info_titleabbrev: Kubernetes policies

include::../attributes.txt[]

include::cni-network-policy-configure.adoc[leveloffset=+1]

include::network-policy-disable.adoc[leveloffset=+1]

include::network-policies-troubleshooting.adoc[leveloffset=+1]

include::network-policy-stars-demo.adoc[leveloffset=+1]

[abstract]
--
Learn how to configure your Amazon EKS cluster to use [.noloc]`Kubernetes` network policies with the [.noloc]`Amazon VPC CNI` plugin. Control network traffic to and from pods using network policies for enhanced security. Covers network policy considerations, requirements, setup instructions, and troubleshooting tips.
--

By default, there are no restrictions in [.noloc]`Kubernetes` for IP addresses, ports, or connections between any [.noloc]`Pods` in your cluster or between your [.noloc]`Pods` and resources in any other network. You can use [.noloc]`Kubernetes` _network policy_ to restrict network traffic to and from your [.noloc]`Pods`. For more information, see https://kubernetes.io/docs/concepts/services-networking/network-policies/[Network Policies] in the [.noloc]`Kubernetes` documentation.

If you have version `1.13` or earlier of the [.noloc]`Amazon VPC CNI plugin for Kubernetes` on your cluster, you need to implement a third party solution to apply [.noloc]`Kubernetes` network policies to your cluster. Version `1.14` or later of the plugin can implement network policies, so you don't need to use a third party solution. In this topic, you learn how to configure your cluster to use [.noloc]`Kubernetes` network policy on your cluster without using a third party add-on.

Network policies in the [.noloc]`Amazon VPC CNI plugin for Kubernetes` are supported in the following configurations.



* Amazon EKS clusters of version `1.25` and later.
* Version 1.14 or later of the [.noloc]`Amazon VPC CNI plugin for Kubernetes` on your cluster.
* Cluster configured for `IPv4` or `IPv6` addresses.
* You can use network policies with <<security-groups-for-pods,security groups for Pods>>. With network policies, you can control all in-cluster communication. With security groups for [.noloc]`Pods`, you can control access to {aws} services from applications within a [.noloc]`Pod`.
* You can use network policies with _custom networking_ and _prefix delegation_.


[#cni-network-policy-considerations]
== Considerations

*Architecture*

* When applying [.noloc]`Amazon VPC CNI plugin for Kubernetes` network policies to your cluster with the [.noloc]`Amazon VPC CNI plugin for Kubernetes` , you can apply the policies to Amazon EC2 Linux nodes only. You can't apply the policies to Fargate or Windows nodes.
* Network policies only apply either `IPv4` or `IPv6` addresses, but not both. In an `IPv4` cluster, the VPC CNI assigns `IPv4` address to pods and applies `IPv4` policies. In an `IPv6` cluster, the VPC CNI assigns `IPv6` address to pods and applies `IPv6` policies. Any `IPv4` network policy rules applied to an `IPv6` cluster are ignored. Any `IPv6` network policy rules applied to an `IPv4` cluster are ignored.

*Network Policies*

* Network Policies are only applied to [.noloc]`Pods` that are part of a [.noloc]`Deployment`. Standalone [.noloc]`Pods` that don't have a `metadata.ownerReferences` set can't have network policies applied to them.
* You can apply multiple network policies to the same [.noloc]`Pod`. When two or more policies that select the same [.noloc]`Pod` are configured, all policies are applied to the [.noloc]`Pod`.
* The maximum number of unique combinations of ports for each protocol in each `ingress:` or `egress:` selector in a network policy is 24.
* For any of your [.noloc]`Kubernetes` services, the service port must be the same as the container port. If you're using named ports, use the same name in the service spec too.

*Migration*

* If your cluster is currently using a third party solution to manage [.noloc]`Kubernetes` network policies, you can use those same policies with the [.noloc]`Amazon VPC CNI plugin for Kubernetes`. However you must remove your existing solution so that it isn't managing the same policies.

*Installation*

* The network policy feature creates and requires a `PolicyEndpoint` Custom Resource Definition (CRD) called `policyendpoints.networking.k8s.aws`. `PolicyEndpoint` objects of the Custom Resource are managed by Amazon EKS. You shouldn't modify or delete these resources.
* If you run pods that use the instance role IAM credentials or connect to the EC2 IMDS, be careful to check for network policies that would block access to the EC2 IMDS. You may need to add a network policy to allow access to EC2 IMDS. For more information, see link:AWSEC2/latest/UserGuide/ec2-instance-metadata.html[Instance metadata and user data,type="documentation"] in the Amazon EC2 User Guide.
+
Pods that use _IAM roles for service accounts_ or _EKS Pod Identity_ don't access EC2 IMDS.
* The [.noloc]`Amazon VPC CNI plugin for Kubernetes` doesn't apply network policies to additional network interfaces for each pod, only the primary interface for each pod (`eth0`). This affects the following architectures:
+
** `IPv6` pods with the `ENABLE_V4_EGRESS` variable set to `true`. This variable enables the `IPv4` egress feature to connect the IPv6 pods to `IPv4` endpoints such as those outside the cluster. The `IPv4` egress feature works by creating an additional network interface with a local loopback IPv4 address.
** When using chained network plugins such as [.noloc]`Multus`. Because these plugins add network interfaces to each pod, network policies aren't applied to the chained network plugins.


üìù https://github.com/search?q=repo%3Aawsdocs%2Famazon-eks-user-guide+%5B%23cni-network-policy%5D&type=code[Edit this page on GitHub]